fs.checkpoint.dir=${hadoop.tmp.dir}/dfs/namesecondary
fs.checkpoint.edits.dir=${fs.checkpoint.dir}
fs.checkpoint.period=3600
fs.checkpoint.size=67108864
fs.default.name=file:///
fs.file.impl=org.apache.hadoop.fs.LocalFileSystem
fs.ftp.impl=org.apache.hadoop.fs.ftp.FTPFileSystem
fs.har.impl=org.apache.hadoop.fs.HarFileSystem
fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem
fs.hftp.impl=org.apache.hadoop.hdfs.HftpFileSystem
fs.hsftp.impl=org.apache.hadoop.hdfs.HsftpFileSystem
fs.kfs.impl=org.apache.hadoop.fs.kfs.KosmosFileSystem
fs.ramfs.impl=org.apache.hadoop.fs.InMemoryFileSystem
fs.s3.block.size=67108864
fs.s3.buffer.dir=${hadoop.tmp.dir}/s3
fs.s3.impl=org.apache.hadoop.fs.s3.S3FileSystem
fs.s3.maxRetries=4
fs.s3.sleepTimeSeconds=10
fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem
fs.trash.interval=0
group.name=grad
hadoop.job.ugi=rares,grad,adm,dialout,cdrom,floppy,audio,dip,www-data,video,plugdev,fuse,lpadmin,admin
hadoop.logfile.count=10
hadoop.logfile.size=10000000
hadoop.native.lib=true
hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
hadoop.security.authorization=false
hadoop.tmp.dir=/tmp/hadoop-${user.name}
hadoop.util.hash.type=murmur
io.bytes.per.checksum=512
io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec
io.file.buffer.size=4096
io.map.index.skip=0
io.mapfile.bloom.error.rate=0.005
io.mapfile.bloom.size=1048576
io.seqfile.compress.blocksize=1000000
io.seqfile.lazydecompress=true
io.seqfile.sorter.recordlimit=1000000
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization
io.skip.checksum.errors=false
io.sort.factor=10
io.sort.mb=100
io.sort.record.percent=0.05
io.sort.spill.percent=0.80
ipc.client.connect.max.retries=10
ipc.client.connection.maxidletime=10000
ipc.client.idlethreshold=4000
ipc.client.kill.max=10
ipc.client.tcpnodelay=false
ipc.server.listen.queue.size=128
ipc.server.tcpnodelay=false
job.end.retry.attempts=0
job.end.retry.interval=30000
jobclient.output.filter=FAILED
keep.failed.task.files=false
local.cache.size=10737418240
map.sort.class=org.apache.hadoop.util.QuickSort
mapred.acls.enabled=false
mapred.child.java.opts=-Xmx200m
mapred.child.tmp=./tmp
mapred.compress.map.output=false
mapred.inmem.merge.threshold=1000
mapred.input.dir=file:/data/raw/dblp/dblp_small.normlower.txt
mapred.job.id=job_local_0001
mapred.job.name=fuzzyjoin.datagen
mapred.job.queue.name=default
mapred.job.reduce.input.buffer.percent=0.0
mapred.job.reuse.jvm.num.tasks=1
mapred.job.shuffle.input.buffer.percent=0.70
mapred.job.shuffle.merge.percent=0.66
mapred.job.split.file=file:/tmp/hadoop-rares/mapred/system/job_local_0001/job.split
mapred.job.tracker.handler.count=10
mapred.job.tracker.http.address=0.0.0.0:50030
mapred.job.tracker.persist.jobstatus.active=false
mapred.job.tracker.persist.jobstatus.dir=/jobtracker/jobsInfo
mapred.job.tracker.persist.jobstatus.hours=0
mapred.job.tracker=local
mapred.jobtracker.completeuserjobs.maximum=100
mapred.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
mapred.jobtracker.job.history.block.size=3145728
mapred.jobtracker.maxtasks.per.job=-1
mapred.jobtracker.restart.recover=false
mapred.jobtracker.taskScheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler
mapred.line.input.format.linespermap=1
mapred.local.dir.minspacekill=0
mapred.local.dir.minspacestart=0
mapred.local.dir=${hadoop.tmp.dir}/mapred/local
mapred.map.max.attempts=4
mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
mapred.map.tasks.speculative.execution=true
mapred.map.tasks=1
mapred.mapper.new-api=true
mapred.max.tracker.blacklists=4
mapred.max.tracker.failures=4
mapred.merge.recordsBeforeProgress=10000
mapred.min.split.size=9223372036854775807
mapred.output.compress=false
mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
mapred.output.compression.type=RECORD
mapred.output.dir=out/datagen/dblp_small
mapred.output.key.class=edu.brown.cs.mapreduce.datastructures.Record
mapred.output.value.class=org.apache.hadoop.io.NullWritable
mapred.queue.default.acl-administer-jobs=*
mapred.queue.default.acl-submit-job=*
mapred.queue.names=default
mapred.reduce.copy.backoff=300
mapred.reduce.max.attempts=4
mapred.reduce.parallel.copies=5
mapred.reduce.slowstart.completed.maps=0.05
mapred.reduce.tasks.speculative.execution=true
mapred.reduce.tasks=0
mapred.skip.attempts.to.start.skipping=2
mapred.skip.map.auto.incr.proc.count=true
mapred.skip.map.max.skip.records=0
mapred.skip.on=false
mapred.skip.reduce.auto.incr.proc.count=true
mapred.skip.reduce.max.skip.groups=0
mapred.submit.replication=10
mapred.system.dir=${hadoop.tmp.dir}/mapred/system
mapred.task.cache.levels=2
mapred.task.default.maxvmem=-1
mapred.task.id=attempt_local_0001_m_000000_0
mapred.task.is.map=true
mapred.task.limit.maxvmem=-1
mapred.task.maxpmem=-1
mapred.task.maxvmem=-1
mapred.task.partition=0
mapred.task.profile.maps=0-2
mapred.task.profile.reduces=0-2
mapred.task.profile=false
mapred.task.timeout=600000
mapred.task.tracker.http.address=0.0.0.0:50060
mapred.task.tracker.report.address=127.0.0.1:0
mapred.tasktracker.dns.interface=default
mapred.tasktracker.dns.nameserver=default
mapred.tasktracker.expiry.interval=600000
mapred.tasktracker.indexcache.mb=10
mapred.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
mapred.tasktracker.map.tasks.maximum=2
mapred.tasktracker.pmem.reserved=-1
mapred.tasktracker.procfsbasedprocesstree.sleeptime-before-sigkill=5000
mapred.tasktracker.reduce.tasks.maximum=2
mapred.tasktracker.taskmemorymanager.monitoring-interval=5000
mapred.tasktracker.vmem.reserved=-1
mapred.temp.dir=${hadoop.tmp.dir}/mapred/temp
mapred.tip.id=task_local_0001_m_000000
mapred.used.genericoptionsparser=true
mapred.userlog.limit.kb=0
mapred.userlog.retain.hours=24
mapred.work.output.dir=file:/home/rares/asterix/asterix/trunk/sandbox/benchmarks/mapreduce/out/datagen/dblp_small
mapred.working.dir=file:/home/rares/asterix/asterix/trunk/sandbox/benchmarks/mapreduce
mapreduce.map.class=edu.brown.cs.mapreduce.benchmarks.fuzzyjoin.DataGen$Map
tasktracker.http.threads=40
topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
topology.script.number.args=100
user.name=rares
webinterface.private.actions=false
